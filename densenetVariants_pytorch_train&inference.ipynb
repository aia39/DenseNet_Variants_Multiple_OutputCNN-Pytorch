{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\gputest\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\User\\Anaconda3\\envs\\gputest\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\User\\Anaconda3\\envs\\gputest\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "data0 = pd.read_feather('train_data_0.feather')\n",
    "data1 = pd.read_feather('train_data_1.feather')\n",
    "data2 = pd.read_feather('train_data_2.feather')\n",
    "data3 = pd.read_feather('train_data_3.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.concat([data0,data1,data2,data3],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphemeDataset(Dataset):\n",
    "    def __init__(self,df,label,_type='train'):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        label1 = self.label.vowel_diacritic.values[idx]\n",
    "        label2 = self.label.grapheme_root.values[idx]\n",
    "        label3 = self.label.consonant_diacritic.values[idx]\n",
    "        image = self.df.iloc[idx][1:].values.reshape(64,64).astype(np.float)\n",
    "        return image,label1,label2,label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, expansion=1, growthRate=32, dropRate=0):\n",
    "        super(DenseBasicBlock, self).__init__()\n",
    "        planes = expansion * growthRate\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "\n",
    "        out = torch.cat((x, out), 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseBottleneck(nn.Module):\n",
    "    def __init__(self, inplanes, expansion=4, growthRate=32, dropRate=0):\n",
    "        super(DenseBottleneck, self).__init__()\n",
    "        planes = expansion * growthRate\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "\n",
    "        out = torch.cat((x, out), 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1, stride=1,\n",
    "                               bias=False)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.avgpool(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, bottleneck=True, growthRate=32, head7x7=True, dropRate=0,\n",
    "                 increasingRate=1, compressionRate=2, layers=(6, 12, 32, 32)):\n",
    "        \"\"\"\n",
    "        For constructuing multiple densenet variants change 'layers' argument to :\n",
    "        (2, 2, 2, 2) for densenet21 # growthRate=24\n",
    "        (3, 4, 6, 3) for densenet37 # growthRate=24\n",
    "        (4, 6, 8, 4) for densenet49 # growthRate=24\n",
    "        (4, 8, 16, 8) for densenet77\n",
    "        (6, 12, 24, 16) for densenet121\n",
    "        (6, 12, 32, 32) for densenet169\n",
    "        (6, 12, 48, 32) for densenet201\n",
    "        (6, 12, 64, 48) for densenet264\n",
    "        (6, 12, 36, 24) for densenet161 # growthRate=48\n",
    "        (6, 12, 64, 48) for densenet264_g48 # growthRate=48\n",
    "        note: if you use head7x7=False, the actual depth of densenet will increase by 2 layers.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(DenseNet, self).__init__()\n",
    "        if bottleneck:\n",
    "            block = DenseBottleneck\n",
    "        else:\n",
    "            block = DenseBasicBlock\n",
    "\n",
    "        self.growthRate = growthRate\n",
    "        self.dropRate = dropRate\n",
    "        self.increasingRate = increasingRate\n",
    "        headplanes = growthRate * pow(increasingRate, 2)\n",
    "        self.inplanes = headplanes * 2  # default 64\n",
    "\n",
    "        self.head7x7 = head7x7\n",
    "        if self.head7x7:\n",
    "            self.conv1 = nn.Conv2d(1, headplanes * 2, 7, 2, 3, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(headplanes * 2)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(1, headplanes, 3, 2, 1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(headplanes)\n",
    "            self.conv2 = nn.Conv2d(headplanes, headplanes, 3, 1, 1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(headplanes)\n",
    "            self.conv3 = nn.Conv2d(headplanes, headplanes * 2, 3, 1, 1, bias=False)\n",
    "            self.bn3 = nn.BatchNorm2d(headplanes * 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Dense-Block 1 and transition (56x56)\n",
    "        self.dense1 = self._make_layer(block, layers[0])\n",
    "        self.trans1 = self._make_transition(compressionRate)\n",
    "        # Dense-Block 2 and transition (28x28)\n",
    "        self.dense2 = self._make_layer(block, layers[1])\n",
    "        self.trans2 = self._make_transition(compressionRate)\n",
    "        # Dense-Block 3 and transition (14x14)\n",
    "        self.dense3 = self._make_layer(block, layers[2])\n",
    "        self.trans3 = self._make_transition(compressionRate)\n",
    "        # Dense-Block 4 (14x14)\n",
    "        self.dense4 = self._make_layer(block, layers[3])\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(self.inplanes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        # vowel_diacritic\n",
    "        self.fc1 = nn.Linear(self.inplanes,11)\n",
    "        # grapheme_root\n",
    "        self.fc2 = nn.Linear(self.inplanes,168)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(self.inplanes,7)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, blocks):\n",
    "        \"\"\" Stack n bottleneck modules where n is inferred from the depth of the network.\n",
    "        Args:\n",
    "            block: block type used to construct DenseNet\n",
    "            blocks: number of blocks to be built\n",
    "        Returns: a Module consisting of n sequential bottlenecks.\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        for i in range(blocks):\n",
    "            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n",
    "            self.inplanes += self.growthRate\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_transition(self, compressionRate):\n",
    "        inplanes = self.inplanes\n",
    "        outplanes = int(math.floor(self.inplanes // compressionRate))\n",
    "        self.inplanes = outplanes\n",
    "        self.growthRate *= self.increasingRate\n",
    "        return Transition(inplanes, outplanes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.head7x7:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.trans1(self.dense1(x))\n",
    "        x = self.trans2(self.dense2(x))\n",
    "        x = self.trans3(self.dense3(x))\n",
    "        x = self.dense4(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        x3 = self.fc3(x)\n",
    "        return x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ResNet50().to(device)\n",
    "model=DenseNet().to(device)\n",
    "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=0.05)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1/3 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022f1873b1eb411d93085532380f54c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc : 38.3509%\n",
      "loss : 7.4335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db94560dd36c4ec38d46376153679f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc : 49.4072%\n",
      "va_loss : 6.0458\n",
      "epochs 2/3 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da328c48493b43c790af0ce0d52c6813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc : 53.3740%\n",
      "loss : 5.4795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430f10e734a346a3be885597cb2b10d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc : 56.7412%\n",
      "va_loss : 4.8611\n",
      "epochs 3/3 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572877bea94147c082877332840262e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc : 58.3223%\n",
      "loss : 4.5914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcf46fcc91f4aa7ba210bc7e10d5e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc : 62.4238%\n",
      "va_loss : 4.0513\n"
     ]
    }
   ],
   "source": [
    "#training + validation\n",
    "epochs = 3\n",
    "model.train()\n",
    "losses = []\n",
    "accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "for epoch in range(epochs):\n",
    "    train_index =train.groupby(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']).apply(lambda x: x.sample(5)).image_id.values\n",
    "    reduced_train = train.loc[train.image_id.isin(train_index)]\n",
    "    train_data = data_full.loc[data_full.image_id.isin(train_index)]\n",
    "    \n",
    "    train_image = GraphemeDataset(train_data,reduced_train)\n",
    "    \n",
    "    \n",
    "    ##data for training\n",
    "    train_loader = torch.utils.data.DataLoader(train_image,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    test_index =train.groupby(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']).apply(lambda x: x.sample(1)).image_id.values\n",
    "    reduced_test = train.loc[train.image_id.isin(test_index)]\n",
    "    test_data = data_full.loc[data_full.image_id.isin(test_index)]\n",
    "    \n",
    "    test_image = GraphemeDataset(test_data,reduced_test)\n",
    "    \n",
    "    ##data for test\n",
    "    test_loader = torch.utils.data.DataLoader(test_image,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    print('epochs {}/{} '.format(epoch+1,epochs))\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for idx, (inputs,labels1,labels2,labels3) in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels1 = labels1.to(device)\n",
    "        labels2 = labels2.to(device)\n",
    "        labels3 = labels3.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs1,outputs2,outputs3 = model(inputs.unsqueeze(1).float())\n",
    "        loss1 = criterion(outputs1,labels1)\n",
    "        loss2 = criterion(outputs2,labels2)\n",
    "        loss3 = criterion(outputs3,labels3)\n",
    "        running_loss += loss1+loss2+loss3\n",
    "        running_acc += (outputs1.argmax(1)==labels1).float().mean()\n",
    "        running_acc += (outputs2.argmax(1)==labels2).float().mean()\n",
    "        running_acc += (outputs3.argmax(1)==labels3).float().mean()\n",
    "        (loss1+loss2+loss3).backward()\n",
    "        optimizer.step()\n",
    "    #scheduler.step()\n",
    "    losses.append(running_loss/len(train_loader))\n",
    "    accs.append(running_acc/(len(train_loader)*3))\n",
    "    print('acc : {:.4f}%'.format(running_acc*100/(len(train_loader)*3)))\n",
    "    print('loss : {:.4f}'.format(running_loss/len(train_loader)))\n",
    "    \n",
    "    ## data feed for validation\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for idx, (inputs,labels1,labels2,labels3) in tqdm(enumerate(test_loader),total=len(test_loader)):  #here tqdm is used for progressbar and total=len(t..) means prpgress bar highest value is len(t..)\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels1 = labels1.to(device)\n",
    "            labels2 = labels2.to(device)\n",
    "            labels3 = labels3.to(device)\n",
    "            \n",
    "            outputs1,outputs2,outputs3 = model(inputs.unsqueeze(1).float())\n",
    "            \n",
    "            loss1 = criterion(outputs1,labels1)\n",
    "            loss2 = criterion(outputs2,labels2)\n",
    "            loss3 = criterion(outputs3,labels3)\n",
    "            running_loss += loss1+loss2+loss3\n",
    "            running_acc += (outputs1.argmax(1)==labels1).float().mean()\n",
    "            running_acc += (outputs2.argmax(1)==labels2).float().mean()\n",
    "            running_acc += (outputs3.argmax(1)==labels3).float().mean()\n",
    "            \n",
    "        \n",
    "        val_losses.append(running_loss/len(test_loader))\n",
    "        val_accs.append(running_acc/(len(test_loader)*3))\n",
    "        print('val_acc : {:.4f}%'.format(running_acc*100/(len(test_loader)*3)))\n",
    "        print('va_loss : {:.4f}'.format(running_loss/len(test_loader)))\n",
    "            \n",
    "torch.save(model.state_dict(), 'Densesaved_weightsTrained50.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFERENCE PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphemeDataset(Dataset):\n",
    "    def __init__(self,df,_type='train'):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        image = self.df.iloc[idx][1:].values.reshape(64,64).astype(float)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNet().to(device)\n",
    "model.load_state_dict(torch.load('dense_saved_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resize(df,size=64):\n",
    "    resized = {} \n",
    "    df = df.set_index('image_id')\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n",
    "        resized[df.index[i]] = image.reshape(-1)\n",
    "    resized = pd.DataFrame(resized).T.reset_index()\n",
    "    resized.columns = resized.columns.astype(str)\n",
    "    resized.rename(columns={'index':'image_id'},inplace=True)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcc0cce0d2644c1bcf4a8de15488ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3d829618a6440393148b08800076d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbab8fc2bef14cd8a99e4d8add834b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762df1fd566c43b6ab2cbb8c6f4c691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969232dfcbba4308b5dae705759eb44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c8f49e7fc045e5be35b83239b71385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3da63422d7240938043c54d1c0019bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670ec50995f64100bd784f7761a42986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "model.eval()\n",
    "test_data = ['test_image_data_0.parquet','test_image_data_1.parquet','test_image_data_2.parquet','test_image_data_3.parquet']\n",
    "predictions = []\n",
    "batch_size=1\n",
    "for fname in test_data:\n",
    "    data = pd.read_parquet(f'{fname}')\n",
    "    data = Resize(data)\n",
    "    test_image = GraphemeDataset(data)\n",
    "    test_loader = torch.utils.data.DataLoader(test_image,batch_size=1,shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs) in tqdm(enumerate(test_loader),total=len(test_loader)):\n",
    "            inputs.to(device)\n",
    "            \n",
    "            outputs1,outputs2,outputs3 = model(inputs.unsqueeze(1).float().cuda())\n",
    "            predictions.append(outputs3.argmax(1).cpu().detach().numpy())\n",
    "            predictions.append(outputs2.argmax(1).cpu().detach().numpy())\n",
    "            predictions.append(outputs1.argmax(1).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Test_2_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Test_2_grapheme_root</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Test_2_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Test_3_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id  target\n",
       "0  Test_0_consonant_diacritic       0\n",
       "1        Test_0_grapheme_root      96\n",
       "2      Test_0_vowel_diacritic       1\n",
       "3  Test_1_consonant_diacritic       0\n",
       "4        Test_1_grapheme_root      93\n",
       "5      Test_1_vowel_diacritic       2\n",
       "6  Test_2_consonant_diacritic       0\n",
       "7        Test_2_grapheme_root     141\n",
       "8      Test_2_vowel_diacritic       0\n",
       "9  Test_3_consonant_diacritic       0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.target = np.hstack(predictions)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissiondense.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
